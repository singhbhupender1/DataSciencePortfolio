{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis with RNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2wUI09NO8OQ",
        "colab_type": "text"
      },
      "source": [
        "#RNNs\n",
        "We will use Recurrent Neural Networks, and in particular LSTMs, to perform sentiment analysis in Keras. Conveniently, Keras has a built-in IMDb movie reviews dataset that we can use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2ZhEAskN0eT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65cc06f8-cdf1-43f5-c415-b0aae9a4aa83"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An2vlhUWNNgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import imdb\n",
        "import warnings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFGCPIc_Nv1G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "66a03fb7-9712-496c-cbda-82e936fa2276"
      },
      "source": [
        "vocabulary_size = 5000\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)\n",
        "print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 3s 0us/step\n",
            "Loaded dataset with 25000 training samples, 25000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndehve9uPDfk",
        "colab_type": "text"
      },
      "source": [
        "Inspect a sample review and its label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojgr67eNOG5x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "b312c2b5-cf17-4507-ebbe-6ca0dd1053b1"
      },
      "source": [
        "print('---review---')\n",
        "print(X_train[6])\n",
        "print('---label---')\n",
        "print(y_train[6])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---review---\n",
            "[1, 2, 365, 1234, 5, 1156, 354, 11, 14, 2, 2, 7, 1016, 2, 2, 356, 44, 4, 1349, 500, 746, 5, 200, 4, 4132, 11, 2, 2, 1117, 1831, 2, 5, 4831, 26, 6, 2, 4183, 17, 369, 37, 215, 1345, 143, 2, 5, 1838, 8, 1974, 15, 36, 119, 257, 85, 52, 486, 9, 6, 2, 2, 63, 271, 6, 196, 96, 949, 4121, 4, 2, 7, 4, 2212, 2436, 819, 63, 47, 77, 2, 180, 6, 227, 11, 94, 2494, 2, 13, 423, 4, 168, 7, 4, 22, 5, 89, 665, 71, 270, 56, 5, 13, 197, 12, 161, 2, 99, 76, 23, 2, 7, 419, 665, 40, 91, 85, 108, 7, 4, 2084, 5, 4773, 81, 55, 52, 1901]\n",
            "---label---\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3lQNiX9PGx6",
        "colab_type": "text"
      },
      "source": [
        "Map word IDs back to words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYmTAWJVOKy9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "01d56e1d-9dab-44a7-d877-40f5b25a6e39"
      },
      "source": [
        "word2id = imdb.get_word_index()\n",
        "id2word = {i: word for word, i in word2id.items()}\n",
        "print('---review with words---')\n",
        "print([id2word.get(i, ' ') for i in X_train[6]])\n",
        "print('---label---')\n",
        "print(y_train[6])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 2s 1us/step\n",
            "---review with words---\n",
            "['the', 'and', 'full', 'involving', 'to', 'impressive', 'boring', 'this', 'as', 'and', 'and', 'br', 'villain', 'and', 'and', 'need', 'has', 'of', 'costumes', 'b', 'message', 'to', 'may', 'of', 'props', 'this', 'and', 'and', 'concept', 'issue', 'and', 'to', \"god's\", 'he', 'is', 'and', 'unfolds', 'movie', 'women', 'like', \"isn't\", 'surely', \"i'm\", 'and', 'to', 'toward', 'in', \"here's\", 'for', 'from', 'did', 'having', 'because', 'very', 'quality', 'it', 'is', 'and', 'and', 'really', 'book', 'is', 'both', 'too', 'worked', 'carl', 'of', 'and', 'br', 'of', 'reviewer', 'closer', 'figure', 'really', 'there', 'will', 'and', 'things', 'is', 'far', 'this', 'make', 'mistakes', 'and', 'was', \"couldn't\", 'of', 'few', 'br', 'of', 'you', 'to', \"don't\", 'female', 'than', 'place', 'she', 'to', 'was', 'between', 'that', 'nothing', 'and', 'movies', 'get', 'are', 'and', 'br', 'yes', 'female', 'just', 'its', 'because', 'many', 'br', 'of', 'overly', 'to', 'descent', 'people', 'time', 'very', 'bland']\n",
            "---label---\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmbNEQx2PL-l",
        "colab_type": "text"
      },
      "source": [
        "Maximum review length and minimum review length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH75_9R_OQyM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87fcd450-851c-409a-e1de-b62831252bb4"
      },
      "source": [
        "print('Maximum review length: {}'.format(\n",
        "len(max((X_train + X_test), key=len))))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum review length: 2697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TckVFKMWOUTu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a01b361-04cd-4c4f-a5cc-75a75e80bce1"
      },
      "source": [
        "print('Minimum review length: {}'.format(\n",
        "len(min((X_test + X_test), key=len))))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum review length: 14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElobDTPwPQdV",
        "colab_type": "text"
      },
      "source": [
        "##Pad sequences\n",
        "In order to feed this data into our RNN, all input documents must have the same length. We will limit the maximum review length to max_words by truncating longer reviews and padding shorter reviews with a null value (0). We can accomplish this using the pad_sequences() function in Keras. For now, set max_words to 500."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ9Ul2m1OX0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "\n",
        "max_words = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_esAehPzPYRE",
        "colab_type": "text"
      },
      "source": [
        "##TODO: Design an RNN model for sentiment analysis\n",
        "Build our model architecture in the code cell below. We have imported some layers from Keras that you might need but feel free to use any other layers / transformations you like.\n",
        "\n",
        "Remember that our input is a sequence of words (technically, integer word IDs) of maximum length = max_words, and our output is a binary sentiment label (0 or 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4_4S4i3OeWb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "90062d71-cc6b-4f97-8cb8-9e0522382815"
      },
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "embedding_size=32\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_b2uKUdPhHu",
        "colab_type": "text"
      },
      "source": [
        "To summarize, our model is a simple RNN model with 1 embedding, 1 LSTM and 1 dense layers. 213,301 parameters in total need to be trained.\n",
        "\n",
        "##Train and evaluate our model\n",
        "We first need to compile our model by specifying the loss function and optimizer we want to use while training, as well as any evaluation metrics we'd like to measure. Specify the approprate parameters, including at least one metric 'accuracy'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBWF8hzgOiir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "8cdee6bb-b413-4b92-e109-7118e806933d"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', \n",
        "             optimizer='adam', \n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnRiN3gxPqWo",
        "colab_type": "text"
      },
      "source": [
        "Once compiled, we can kick off the training process. There are two important training parameters that we have to specify - batch size and number of training epochs, which together with our model architecture determine the total training time.\n",
        "\n",
        "Training may take a while, so grab a cup of coffee, or better, go for a run!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAT_ehUCOmsA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "outputId": "664f3275-1765-4527-e206-c34c0aab9420"
      },
      "source": [
        "batch_size = 64\n",
        "num_epochs = 3\n",
        "\n",
        "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
        "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
        "\n",
        "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 24936 samples, validate on 64 samples\n",
            "Epoch 1/3\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "24936/24936 [==============================] - 334s 13ms/step - loss: 0.4548 - acc: 0.7852 - val_loss: 0.1871 - val_acc: 0.9375\n",
            "Epoch 2/3\n",
            "24936/24936 [==============================] - 318s 13ms/step - loss: 0.2844 - acc: 0.8890 - val_loss: 0.2045 - val_acc: 0.9375\n",
            "Epoch 3/3\n",
            "24936/24936 [==============================] - 320s 13ms/step - loss: 0.2331 - acc: 0.9091 - val_loss: 0.1972 - val_acc: 0.9062\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc6781f5a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wpxu0wJwPuuN",
        "colab_type": "text"
      },
      "source": [
        "scores[1] will correspond to accuracy if we pass metrics=['accuracy']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXuYlJd7O1Gy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79a7aebd-1bb0-485e-fc93-8de15ad897f1"
      },
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.87124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enOdhwGvOGAx",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}